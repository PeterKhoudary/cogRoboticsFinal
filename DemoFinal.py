from cozmo_fsm import *

import os
import numpy as np
import cv2
import base64
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

preamble = """
Imagine you are a robot navigating through terrain. 
If you see what appears to be a cube with some insignia on it,
the cube is 45 mm on a side. You might think these
cubes are themselves robots, but you can be assured they are merely stylized cubes.
If you are asked to provide dimesional information (width, height) about your surroundings,
just give your best guess, even if you think it is inaccurate.
Note that if the size / appearance of objects in your view appears to change, it is because 
the robot moved, and not that your environment changed. You will be asked to estimate
distances / heights / widths of these objects, and distance may be relative to your new position.
That is, objects which are visible at first may no longer be in subsequent images, but you can
rest assured that the objects haven't moved, but rather the robot you're piloting has.
Assume all units are millimeters.
"""

runningHistory = [{"role": "system", "content": preamble}]

userInput = ""


class GetImage(StateNode):
    def start(self, event=None):
        super().start(event)
        global userInput
        userInput = event.string
        img = np.array(self.robot.world.latest_image.raw_image)
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 95]
        result, encimg = cv2.imencode('.jpg', img, encode_param)
        jpeg_string = base64.b64encode(encimg).decode('utf-8')
        self.post_data(jpeg_string)

class RunQuery(StateNode):
    def start(self,event):
        super().start(event)

        global runningHistory
        global userInput

        jpeg_string = event.data

        query = f"Your current position is {robot.pose.position}. " + userInput  

        premise = "Please note in the image you are about to see: "
        emptyLen = len(premise)

        cubeNameData = [('cube1', cube1, wcube1), ('cube2', cube2, wcube2), ('cube3', cube3, wcube3)]
        for (name, cube, wcube) in cubeNameData:

            # Visibility
            if cube.is_visible: 
                premise += f'{name} is visible. \n'
                # Orientation
                premise += f'{name} orientation is {wcube.orientation}.\n'

                # Position
                premise += f'{name} position is {str(cube.pose.position)}.\n'
            else: 
                premise += f'{name} is not visible. \n'
          
        query = premise + " " + query if (len(premise) != emptyLen) else query

        response = self.parent.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages = runningHistory + [
            {"role": "user", "content": [
                { "type": "text",
                  "text": query
                },
                { "type": "image_url",
                  "image_url": { "url" : f"data:image/jpeg;base64,{jpeg_string}"}
                }
                ]
            }]
        )
        # print(response.choices[0].message.content)
        for choice in response.choices:
            # remove LaTeX brackets from response
            cleaned_response = re.sub(r'\\[\[\]\(\)]', '', choice.message.content)
            print(cleaned_response)
        
        runningHistory += [{"role": "user", "content": [
                              { "type": "text",
                                "text": query
                              },
                              { "type": "image_url",
                                "image_url": { "url" : f"data:image/jpeg;base64,{jpeg_string}"}
                              }
                            ]},

                          {"role": "assistant", "content": cleaned_response}
                          ]
        print()
        self.post_completion()


class DemoFinal(StateMachineProgram):
    def start(self):
        super().start()
        self.client = openai.OpenAI()
 
    def setup(self):
        #         # Allow time for color vision to kick in
        #         ColorImageEnabled() =T(1)=> wait
        # 
        #         wait: Print("Enter 'tm' followed by a question for cozmo") =TM=> get_image
        # 
        #         get_image: GetImage() =D=> RunQuery() =C=> wait
        
        # Code generated by genfsm on Fri Apr 19 16:34:01 2024:
        
        colorimageenabled1 = ColorImageEnabled() .set_name("colorimageenabled1") .set_parent(self)
        wait = Print("Enter 'tm' followed by a question for cozmo") .set_name("wait") .set_parent(self)
        get_image = GetImage() .set_name("get_image") .set_parent(self)
        runquery1 = RunQuery() .set_name("runquery1") .set_parent(self)
        
        timertrans1 = TimerTrans(1) .set_name("timertrans1")
        timertrans1 .add_sources(colorimageenabled1) .add_destinations(wait)
        
        textmsgtrans1 = TextMsgTrans() .set_name("textmsgtrans1")
        textmsgtrans1 .add_sources(wait) .add_destinations(get_image)
        
        datatrans1 = DataTrans() .set_name("datatrans1")
        datatrans1 .add_sources(get_image) .add_destinations(runquery1)
        
        completiontrans1 = CompletionTrans() .set_name("completiontrans1")
        completiontrans1 .add_sources(runquery1) .add_destinations(wait)
        
        return self
        # print(response.choices[0].message.content)
        for choice in response.choices:
            # remove LaTeX brackets from response
            cleaned_response = re.sub(r'\\[\[\]\(\)]', '', choice.message.content)
            print(cleaned_response)
        
        runningHistory += [{"role": "user", "content": [
                              { "type": "text",
                                "text": userInput
                              },
                              { "type": "image_url",
                                "image_url": { "url" : f"data:image/jpeg;base64,{jpeg_string}"}
                              }
                            ]},

                          {"role": "assistant", "content": cleaned_response}
                          ]
        print()
        self.post_completion()


class DemoFinal(StateMachineProgram):
    def start(self):
        super().start()
        self.client = openai.OpenAI()
 
    def setup(self):
        #         # Allow time for color vision to kick in
        #         SetHeadAngle(0) =T(1)=> wait
        # 
        #         wait: Print("Enter 'tm' followed by a question for cozmo") =TM=> get_image
        # 
        #         get_image: GetImage() =D=> RunQuery() =C=> wait
        
        # Code generated by genfsm on Fri Apr 19 16:34:01 2024:
        
        setheadangle1 = SetHeadAngle(0) .set_name("setheadangle1") .set_parent(self)
        wait = Print("Enter 'tm' followed by a question for cozmo") .set_name("wait") .set_parent(self)
        get_image = GetImage() .set_name("get_image") .set_parent(self)
        runquery2 = RunQuery() .set_name("runquery2") .set_parent(self)
        
        timertrans2 = TimerTrans(1) .set_name("timertrans2")
        timertrans2 .add_sources(setheadangle1) .add_destinations(wait)
        
        textmsgtrans2 = TextMsgTrans() .set_name("textmsgtrans2")
        textmsgtrans2 .add_sources(wait) .add_destinations(get_image)
        
        datatrans2 = DataTrans() .set_name("datatrans2")
        datatrans2 .add_sources(get_image) .add_destinations(runquery2)
        
        completiontrans2 = CompletionTrans() .set_name("completiontrans2")
        completiontrans2 .add_sources(runquery2) .add_destinations(wait)
        
        return self
